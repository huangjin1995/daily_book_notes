天气：阴  
阅读时间：晚  


## chapter 6
几乎所有自然语言处理、信息与信号处理的应用都是一个消除不确定性的过程。  
几乎所有机器学习、深度学习的算法都是一个降低误差的过程。  

信息的作用在于消除不确定性，自然语言处理的大量问题就是寻找相关的信息。

+ 消除不确定性/降低误差  
网页搜索: 搜索词  ->  大量相关的结果  ->  挖掘新的隐含信息（网页的质量信息/用户的真实诉求）  ->  精确的结果  


+ 信息的度量  
信息熵、条件熵、相对熵


+ 互信息的应用  
词义的二义性（又称歧义性，Ambiguation）  
这是规则方法的难点，然而真正简单却非常实用的方法是互信息。  
1). 一个多义词表，假设某多义词含有两个义项a/b.  
2). 从语料中找出和多义词义项a一起出现的互信息最大的词（多义词的上下文）  
3). 再从语料中找出和多义词义项b一起出现的互信息最大的词  
4). 在搜索/翻译时，根据query/translation上下文中哪类相关的词语较多，从而确定当前多义词的含义  


+ 相对熵的应用  
1). 最早应用于信号处理 - 衡量两段信息的相似程度  
2). Google的自动问答系统 - 衡量两个答案的相似性  
3). 同义词判定 - 衡量两个常用词（在语法和语义上）在不同文本中的概率分布  
4). 语言模型复杂度（Perplexity） - 物理含义，即在给定上下文条件下，句子中每个位置平均可以选择的单词数量。  
信息熵 -> 上下文-条件熵 -> 训练语料与真实文本的概率分布-相对熵  
5). ...

