
天气：晴  
阅读时间：白天


## chapter 19
+ 谈谈数学模型的重要性

+ Summary  
1). 一个正确的数学模型应当在形式上是简单的  
2). 大量准确的数据对研发很重要  
3). 正确的模型也可能受噪音干扰，而显得不准确；此时，不应该用一种凑合的修正方法加以弥补，而是找到噪音的根源，也许能通往重大的发现  




天气：晴  
阅读时间：白天


## chapter 20
+ 最大熵模型  
当预测一个随机事件的概率分布时，我们的预测应当满足全部已知的条件，而对未知的情况不要做任何主观假设。此时，概率分布最均匀，预测的风险最小。因为这时概率分布的信息熵最大，所以把这种模型称之为“最大熵模型”。

+ 最大熵模型的训练  
通用迭代算法-GIS(Generalized Iterative Scaling) -> 改进迭代算法-IIS(Improved Iterative Scaling) -> 吴军[1]

+ 最大熵模型的特点  
实现复杂 - 计算量巨大，在工程上实现方法的好坏决定了模型的实用与否；  
应用广泛 - 从形式上看，它非常简单，非常优美；从效果上看，它是唯一一种既能满足各个信息源的限制条件，又能保证平滑性（Smooth）的模型。  

+ 最大熵模型的应用场景  
1). 词性标注/句法分析  
拉纳帕提（Adwait Ratnaparkhi）将上下文信息、词性及主谓宾等句子成分，通过最大熵模型结合起来，做出了当时世界上最好的词性标识系统（至今仍然是使用单一方法的系统中效果最好的）和句法分析器。

+ Summary  
如何用一个统一的模型将各种各样但又不完全确定的信息综合起来？这就是最大熵模型解决的问题。  


> reference:  
> [1] www.cs.jhu.edu/~junwu/publications.html  
> Maximum entropy language modeling with non-local dependencies. 2002. Wu, J. Ph.D dissertation, www.cs.jhu.edu/~junwu/publications/dissertation.pdf




天气：晴  
阅读时间：29日-晚
记录时间：30日-晚


## chapter 21
+ 拼音输入法的历史  
以中文输入为例，过去25年里，输入法经历了自然音节输入->偏旁笔画拆字输入->自然音节输入的过程。  

+ 拼音输入法的数学原理  
汉字的编码分为两部分：拼音的编码、消除歧义性的编码  
1). 拼音的编码  
a). 符合直觉，输入自然，不会中断思维  
b). 采用每个汉字编码较长的全拼输入法，由于存在信息冗余，容错性非常好  
2). 消除歧义性的编码(如何利用上下文)  
a). 建立词库  
b). 建立语言模型(拼音转汉字的解码技巧)  
关键在于如何准确而有效地建立语言模型（内存占用小）？

+ 拼音转汉字的算法  
拼音转汉字的算法和在导航中寻找最短路径的算法相同，都是动态规划。  

+ 个性化语言模型  
1). 如何训练一个个性化语言模型  
根据用户用语习惯的语料，训练一个用户特定的语言模型。  
如何找到大量符合用户用语习惯的语料？  
a). 将训练语言模型的文本按照主题分成不同的类别  
b). 针对每个类，找到它们的特征向量（TF-IDF）  
c). 统计用户经常输入的文本，得到输入文本的特征向量  
d). 计算余弦距离  
e). 选择TopK个与用户文本最近的类对应的文本，作为该用户语言模型的训练数据  
f). 训练一个用户特征的语言模型M1  

2). 如何结合个性化语言模型(M1)与通用语言模型(M0)  
通常而言，M1比M0效果好，但对于相对冷僻的内容，M1的效果远不如M0，因为M1训练数据小一两个数量级，覆盖的语言现象少得多。  
a). 最大熵模型  
该模型训练时间较长，建立个性化语言模型的成本较高
b). 线性插值模型  
应用场景-Google拼音输入法的个性化语言模型

> question:  
> Google拼音输入法，如何建立个性化语言模型(Active Learning)?




天气：晴  
阅读时间：白天


## chapter 24
+ 贝叶斯网络（信念网络-Belief Networks）  
贝叶斯网络 - 拓扑结构  
马尔可夫链 - 链状结构  

+ 贝叶斯网络的训练  
????
1). 结构训练-确定网络的拓扑结构  
完备搜索（Exhaustive Search）-> 贪心算法（Greedy Algorithm）-> 互信息  
贪心算法：在每一步时，沿箭头方向寻找有限步，容易陷入局部最优。防止陷入局部最优，可以采用蒙特卡罗方法。  
互信息：计算节点之间两两的互信息，只保留互信息较大的节点直接的连接，再对简化的网络进行完备搜索，找到全局优化的结构。  
2). 参数训练-各个状态之间相关的概率  
最大熵模型 - 根据训练数据，优化贝叶斯网络的参数，使得后验概率最大。

+ 贝叶斯网络的应用场景  
Google搜索和Google广告  
1).查找近义词  
2).利用贝叶斯网络，建立文章、概念和关键词的联系  
关键词 - 在上下文中同现
概念 - 不同颗粒度

+ 通用的贝叶斯网络工具包  
IBM华生实验室-茨威格博士（Geoffrey Zweig）和西雅图华盛顿大学-比尔默教授（Jeff Bilmer）完成了一个通用的贝叶斯网络工具包。  




天气：晴  
阅读时间：白天


## chapter 25




