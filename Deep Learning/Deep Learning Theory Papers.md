### paper

+ Wide Neural Networks of Any Depth Evolve as Linear Models Under Gradient Descent, Jaehoon Lee, Lechao Xiao, Samuel S. Schoenholz, Yasaman Bahri, Jascha Sohl-Dickstein, Jeffrey Pennington, 2019 [arxiv](https://arxiv.org/abs/1902.06720?context=stat.ML) 

  A key contribution of our work is to show that dynamics in parameter space are equivalent to the training dynamics of a model which is affine in the collection of all network parameters, the weights and biases.

+ 

