
天气：晴  
阅读时间：  
记录时间：11月3日-晚

# 第三篇
## 跟波利亚学解题
+ 启发式思维方法  
todo......


从真实的数学历史发展的角度讲授数学，是数学教学法的最佳方法。  
<<数学，确定性的丧失>>，从历史的角度再现了真实的数学发展过程，波利亚的<<How To Solve It>>/<<数学的发现>>/<<数学与猜想>>，从思维的角度再现了数学发现的思维过程，都是极其难得的好书。   


> reference:  
<<How To Solve It>>/<<数学的发现>>/<<数学与猜想>> - 波利亚  
<<数学，确定性的丧失>>

> question:  
机器学习/深度学习，是否可以看成不断试错的过程？可能容易陷入局部最优解？




## 锤子和钉子
+ 锤子 - 如果你手里有一把锤子，所有东西看上去都像钉子  
无论某件工具多么厉害，它也只是工具箱中的一件工具，任何工具都有其适用范畴和前提，视具体情况而使用，始终不要忘记要解决的问题是什么。

+ 钉子 - 如果你想钉一个钉子，所有东西看上去都像是锤子  
如果你心中专注于你想要解决的问题，那么你所看到的东西就会呈现出以往你没有看到的一面。  




## 数学之美番外篇：平凡而又神奇的贝叶斯方法
+ 先验概率与最大似然  
后验概率 = 先验概率 × 最大似然     
1). 最大似然  
a). 当两者的似然程度非常相近时，不能提供可靠的决策（需要借助先验信息）  
b). 最大似然蕴含了贝叶斯奥卡姆剃刀思想，它表示更简单的模型，似然程度越大  
2). 先验概率  
a). 先验信息为决策提供了更多的信息  
b). 先验概率蕴含了传统的奥卡姆剃刀思想，它表示更简单的模型，先验概率越大  


+ 为什么朴素贝叶斯方法令人诧异地好？  
有些独立假设在各个分类之间的分布都是均匀的，所以对于似然的相对大小不产生影响；即便不是如此，也有很大的可能性使各个独立假设所产生的消极影响或积极影响互相抵消，最终导致结果收到的影响不大。[1]


+ 认知神经科学的思维过程  
bottom-up关联提取, top-down预测  
示例：  
1). 拼写纠正  
首先根据错误单词做bottom-up关联提取，提取出有可能是实际单词的那些候选单词；  
然后再对有限的候选单词做top-down预测，计算哪个对于错误单词的预测效力最好。  
（提取方法及实现机制：生物神经网络是根据什么线索提取及如何实现提取机制，目前还是未知的）  
2). 翻译  
首先从句子到语义（一个逐层往上bottom-up抽象的folding过程）;  
然后从语义根据另一门语言的语法展开为另一门语言（一个逐层往下top-down的具体化unfolding过程）。  
3). 层级结构  
单词集合和句子的对应是多对一的，句子和语义的对应也是多对一的，语义和意图的对应还是多对一的，这是个层级体系。  
神经科学的发现也表明大脑的皮层大致有一种层级结构，对应着越来越抽象的各个层面。  
视觉神经系统 - Hawkins在<<On Intelligence>>中提出了一种HTM（Hierarchical Temporal Memory）模型.  


+ 层级贝叶斯模型  
一般的贝叶斯，都是在同一个事物层次上的各个因素之间进行统计推理；而层次贝叶斯，将这些因素背后的因素（原因的原因，原因的原因，以此类推）囊括进来。


+ summary  
1). 先有鸡还是先有蛋?  
贝叶斯学家认为先假设，再让数据说话（先验概率 + 数据 = 后验概率）  
统计学家认为让数据说话（实际上，等同于假设每种猜测的先验概率是均等的）
2). 越是表层的，越是繁复多变  
统计机器学习方法所统计的东西往往处于相当表层（shallow）的层面，因此需要足够的特征做支撑，然而特征越多，就会产生高维稀疏问题。  
高维稀疏问题的解决方法，要么使用避免高维稀疏的技巧，要么直接深入到更深层（deep）的层面观察更本质的联系。  


> question:    
1，统计机器学习方法只能作浅层（shallow）的归纳，而不能作深层（deep）的推理？shallow statistical or deep reasoning?  
2，除隐马尔可夫模型外，还有哪些层级贝叶斯模型？pLDA/LDA？


> reference:  
[1] The Optimality of Naive Bayes, Harry Zhang.

